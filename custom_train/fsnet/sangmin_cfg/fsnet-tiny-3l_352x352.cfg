[net]
# Testing
#batch=1
#subdivisions=1
# Training
batch=128
subdivisions=1
width=352
height=352
channels=3
momentum=0.949
decay=0.0005
angle=15
saturation = 1.5
exposure = 1.5
hue=.1

learning_rate=0.00261
burn_in=1000
max_batches = 150000
policy=steps
steps=20000,40000,60000,80000,100000,120000,140000
scales=.5,.5,.5,.5,.5,.5,.5

[convolutional]
batch_normalize=1
filters=16
size=3
stride=2
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=24
size=3
stride=2
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=32
size=3
stride=2
pad=1
activation=relu

[route]
layers=-1

[convolutional]
batch_normalize=1
filters=16
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=16
size=3
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=16
size=3
stride=1
pad=1
activation=relu

[route]
layers = -1,-3

[convolutional]
batch_normalize=1
filters=32
size=1
stride=1
pad=1
activation=relu

[route]
layers = -6,-1

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=relu

[route]
layers=-1

[convolutional]
batch_normalize=1
filters=64
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=64
size=3
stride=1
pad=1
activation=relu

[route]
layers = -1,-3

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=relu

[route]
layers = -6,-1

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=relu

[route]
layers=-1

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=relu

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=relu

[route]
layers = -1,-3

[convolutional]
batch_normalize=1
filters=256
size=1
stride=1
pad=1
activation=relu

[route]
layers = -6,-1

[maxpool]
size=2
stride=2

[convolutional]
batch_normalize=1
filters=512
size=3
stride=1
pad=1
activation=relu

##################################


[convolutional]
size=1
stride=1
pad=1
filters=48
activation=linear


[yolo]
mask = 6,7,8
anchors = 4,  8,  10, 12,   6, 21,  17, 22,  12, 45,  32, 39,  48, 72,  82,109, 118,186
classes=11
num=9
jitter=.3
scale_x_y = 1.05
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
ignore_thresh = .7
truth_thresh = 1
random=0
resize=1.5
nms_kind=greedynms
beta_nms=0.6

[route]
layers = -3

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=relu

[upsample]
stride=2

[route]
layers = -1, 25

[convolutional]
batch_normalize=1
filters=256
size=3
stride=1
pad=1
activation=relu

[convolutional]
size=1
stride=1
pad=1
filters=48
activation=linear

[yolo]
mask = 3,4,5
anchors = 4,  8,  10, 12,   6, 21,  17, 22,  12, 45,  32, 39,  48, 72,  82,109, 118,186
classes=11
num=9
jitter=.3
scale_x_y = 1.05
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
ignore_thresh = .7
truth_thresh = 1
random=0
resize=1.5
nms_kind=greedynms
beta_nms=0.6


[route]
layers = -3

[convolutional]
batch_normalize=1
filters=128
size=1
stride=1
pad=1
activation=relu

[upsample]
stride=2

[route]
layers = -1, 16

[convolutional]
batch_normalize=1
filters=128
size=3
stride=1
pad=1
activation=relu

[convolutional]
size=1
stride=1
pad=1
filters=48
activation=linear

[yolo]
mask = 0,1,2
anchors = 4,  8,  10, 12,   6, 21,  17, 22,  12, 45,  32, 39,  48, 72,  82,109, 118,186
classes=11
num=9
jitter=.3
scale_x_y = 1.05
cls_normalizer=1.0
iou_normalizer=0.07
iou_loss=ciou
ignore_thresh = .7
truth_thresh = 1
random=0
resize=1.5
nms_kind=greedynms
beta_nms=0.6